{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad06e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f349f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model and data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the trained Random Forest model\n",
    "with open('f1_random_forest_model.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)\n",
    "\n",
    "# Load the encoders\n",
    "with open('label_encoders.pkl', 'rb') as f:\n",
    "    encoders = pickle.load(f)\n",
    "    le_track = encoders['track']\n",
    "    le_driver = encoders['driver']\n",
    "    le_track_type = encoders['track_type']\n",
    "    le_wet_dry = encoders['wet_dry']\n",
    "\n",
    "# Load feature columns\n",
    "with open('feature_columns.pkl', 'rb') as f:\n",
    "    feature_columns = pickle.load(f)\n",
    "\n",
    "# Load the engineered dataset (for historical stats)\n",
    "df_sorted = pd.read_csv('f1_data.csv')\n",
    "\n",
    "print(\"‚úÖ Model and data loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16830322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_race_results(race_name, track_name, year=2025, \n",
    "                         grid_positions=None, weather='dry', \n",
    "                         track_type='circuit', drivers_list=None):\n",
    "    \"\"\"\n",
    "    Predict race finishing positions and identify top 3 podium finishers\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    race_name : str\n",
    "        Name of the Grand Prix (e.g., \"Las Vegas Grand Prix\")\n",
    "    track_name : str\n",
    "        Track name (e.g., \"Las Vegas Strip Circuit\", \"Monza\", \"Spa-Francorchamps\")\n",
    "    year : int\n",
    "        Race year (default: 2025)\n",
    "    grid_positions : dict, optional\n",
    "        Dictionary of {driver_name: grid_position}. If None, uses historical averages.\n",
    "        Example: {'Max VERSTAPPEN': 1, 'Lando NORRIS': 2, ...}\n",
    "    weather : str\n",
    "        'dry' or 'wet' (default: 'dry')\n",
    "    track_type : str\n",
    "        'circuit' or 'street' (default: 'circuit')\n",
    "    drivers_list : list, optional\n",
    "        List of drivers to predict for. If None, uses all active drivers from latest season.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with predictions sorted by predicted position\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üèÅ PREDICTING: {race_name} {year}\")\n",
    "    print(f\"üìç Track: {track_name}\")\n",
    "    print(f\"üå¶Ô∏è  Weather: {weather.upper()}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get active drivers (from most recent data)\n",
    "    if drivers_list is None:\n",
    "        latest_year = df_sorted['year'].max()\n",
    "        active_drivers = df_sorted[df_sorted['year'] == latest_year]['driver_name'].unique()\n",
    "    else:\n",
    "        active_drivers = drivers_list\n",
    "    \n",
    "    print(f\"\\nüèéÔ∏è  Analyzing {len(active_drivers)} drivers...\")\n",
    "    \n",
    "    # Get historical statistics\n",
    "    driver_stats = df_sorted.groupby('driver_name').agg({\n",
    "        'avg_finish': 'first',\n",
    "        'finish_std': 'first',\n",
    "        'race_count': 'first',\n",
    "        'avg_grid': 'first',\n",
    "        'grid_std': 'first',\n",
    "        'avg_pitstops': 'first',\n",
    "        'podium_rate': 'first',\n",
    "        'win_rate': 'first',\n",
    "        'dnf_rate': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Get track-specific stats\n",
    "    track_stats = df_sorted.groupby(['driver_name', 'track']).agg({\n",
    "        'track_avg_finish': 'first',\n",
    "        'track_avg_grid': 'first',\n",
    "        'track_podium_rate': 'first',\n",
    "        'track_race_count': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Prepare predictions\n",
    "    predictions = []\n",
    "    \n",
    "    for driver in active_drivers:\n",
    "        try:\n",
    "            # Get driver's historical stats\n",
    "            driver_data = driver_stats[driver_stats['driver_name'] == driver]\n",
    "            \n",
    "            if len(driver_data) == 0:\n",
    "                print(f\"‚ö†Ô∏è  Skipping {driver} - no historical data\")\n",
    "                continue\n",
    "            \n",
    "            # Get grid position (from input or historical average)\n",
    "            if grid_positions and driver in grid_positions:\n",
    "                grid_pos = grid_positions[driver]\n",
    "            else:\n",
    "                grid_pos = driver_data['avg_grid'].values[0]\n",
    "            \n",
    "            # Get track-specific stats if available\n",
    "            track_data = track_stats[\n",
    "                (track_stats['driver_name'] == driver) & \n",
    "                (track_stats['track'] == track_name)\n",
    "            ]\n",
    "            \n",
    "            if len(track_data) > 0:\n",
    "                track_avg_finish = track_data['track_avg_finish'].values[0]\n",
    "                track_avg_grid = track_data['track_avg_grid'].values[0]\n",
    "                track_podium_rate = track_data['track_podium_rate'].values[0]\n",
    "                track_race_count = track_data['track_race_count'].values[0]\n",
    "            else:\n",
    "                # Use overall stats if no track-specific data\n",
    "                track_avg_finish = driver_data['avg_finish'].values[0]\n",
    "                track_avg_grid = driver_data['avg_grid'].values[0]\n",
    "                track_podium_rate = driver_data['podium_rate'].values[0]\n",
    "                track_race_count = 0\n",
    "            \n",
    "            # Get recent form (last 5 races of this driver)\n",
    "            recent_races = df_sorted[df_sorted['driver_name'] == driver].tail(5)\n",
    "            if len(recent_races) > 0:\n",
    "                recent_form_5 = recent_races['finished_position'].mean()\n",
    "                recent_form_3 = recent_races.tail(3)['finished_position'].mean()\n",
    "                recent_podiums_5 = (recent_races['finished_position'] <= 3).sum()\n",
    "                recent_wins_5 = (recent_races['finished_position'] == 1).sum()\n",
    "            else:\n",
    "                recent_form_5 = driver_data['avg_finish'].values[0]\n",
    "                recent_form_3 = driver_data['avg_finish'].values[0]\n",
    "                recent_podiums_5 = 0\n",
    "                recent_wins_5 = 0\n",
    "            \n",
    "            # Encode categorical variables\n",
    "            try:\n",
    "                track_enc = le_track.transform([track_name])[0]\n",
    "            except:\n",
    "                # If track not in training data, use most common track encoding\n",
    "                print(f\"‚ö†Ô∏è  Track '{track_name}' not in training data, using default\")\n",
    "                track_enc = 0\n",
    "            \n",
    "            driver_enc = le_driver.transform([driver])[0]\n",
    "            track_type_enc = le_track_type.transform([track_type])[0]\n",
    "            wet_dry_enc = le_wet_dry.transform([weather])[0]\n",
    "            \n",
    "            # Create interaction features\n",
    "            grid_advantage = driver_data['avg_grid'].values[0] / (grid_pos + 0.1)\n",
    "            consistency_score = 1 / (1 + driver_data['finish_std'].values[0])\n",
    "            performance_momentum = (driver_data['avg_finish'].values[0] - recent_form_5) / (driver_data['avg_finish'].values[0] + 1)\n",
    "            \n",
    "            # Build feature vector matching training features\n",
    "            features = {\n",
    "                'grid_position': grid_pos,\n",
    "                'avg_finish': driver_data['avg_finish'].values[0],\n",
    "                'finish_std': driver_data['finish_std'].values[0],\n",
    "                'race_count': driver_data['race_count'].values[0],\n",
    "                'avg_grid': driver_data['avg_grid'].values[0],\n",
    "                'grid_std': driver_data['grid_std'].values[0],\n",
    "                'avg_pitstops': driver_data['avg_pitstops'].values[0],\n",
    "                'podium_rate': driver_data['podium_rate'].values[0],\n",
    "                'win_rate': driver_data['win_rate'].values[0],\n",
    "                'dnf_rate': driver_data['dnf_rate'].values[0],\n",
    "                'track_avg_finish': track_avg_finish,\n",
    "                'track_avg_grid': track_avg_grid,\n",
    "                'track_podium_rate': track_podium_rate,\n",
    "                'track_race_count': track_race_count,\n",
    "                'recent_form_5': recent_form_5,\n",
    "                'recent_form_3': recent_form_3,\n",
    "                'recent_podiums_5': recent_podiums_5,\n",
    "                'recent_wins_5': recent_wins_5,\n",
    "                'track_encoded': track_enc,\n",
    "                'track_type_encoded': track_type_enc,\n",
    "                'wet_dry_encoded': wet_dry_enc,\n",
    "                'driver_encoded': driver_enc,\n",
    "                'grid_advantage': grid_advantage,\n",
    "                'consistency_score': consistency_score,\n",
    "                'performance_momentum': performance_momentum,\n",
    "                'year': year\n",
    "            }\n",
    "            \n",
    "            # Make prediction\n",
    "            X_pred = pd.DataFrame([features])[feature_columns]\n",
    "            predicted_position = rf_model.predict(X_pred)[0]\n",
    "            \n",
    "            predictions.append({\n",
    "                'driver': driver,\n",
    "                'predicted_position': predicted_position,\n",
    "                'grid_position': grid_pos,\n",
    "                'podium_rate': driver_data['podium_rate'].values[0],\n",
    "                'win_rate': driver_data['win_rate'].values[0],\n",
    "                'recent_form': recent_form_5,\n",
    "                'track_experience': 'Yes' if track_race_count > 0 else 'No'\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error predicting for {driver}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Create results DataFrame and sort by predicted position\n",
    "    results_df = pd.DataFrame(predictions).sort_values('predicted_position')\n",
    "    results_df['predicted_rank'] = range(1, len(results_df) + 1)\n",
    "    \n",
    "    # Display top 10 predictions\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèÜ PREDICTED RACE RESULTS - TOP 10\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Rank':<6} {'Driver':<22} {'Pred Pos':<10} {'Grid':<8} {'Podium%':<10} {'Recent Form':<12}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for idx, row in results_df.head(10).iterrows():\n",
    "        rank = row['predicted_rank']\n",
    "        medal = \"ü•á\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\" if rank == 3 else f\"P{rank}\"\n",
    "        print(f\"{medal:<6} {row['driver']:<22} {row['predicted_position']:<10.2f} \"\n",
    "              f\"P{row['grid_position']:<7.0f} {row['podium_rate']*100:<9.1f}% \"\n",
    "              f\"P{row['recent_form']:<11.2f}\")\n",
    "    \n",
    "    # Highlight podium predictions\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèÅ PREDICTED PODIUM (TOP 3)\")\n",
    "    print(\"=\"*80)\n",
    "    podium = results_df.head(3)\n",
    "    for idx, row in podium.iterrows():\n",
    "        rank = row['predicted_rank']\n",
    "        medal = \"ü•á 1st\" if rank == 1 else \"ü•à 2nd\" if rank == 2 else \"ü•â 3rd\"\n",
    "        print(f\"{medal:8} | {row['driver']:<20} | Predicted: P{row['predicted_position']:.2f} | Grid: P{row['grid_position']:.0f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35103183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèÅ PREDICTING: Las Vegas Grand Prix 2025\n",
      "üìç Track: Las Vegas\n",
      "üå¶Ô∏è  Weather: DRY\n",
      "================================================================================\n",
      "\n",
      "üèéÔ∏è  Analyzing 22 drivers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèÜ PREDICTED RACE RESULTS - TOP 10\n",
      "================================================================================\n",
      "Rank   Driver                 Pred Pos   Grid     Podium%    Recent Form \n",
      "--------------------------------------------------------------------------------\n",
      "ü•á      Charles LECLERC        3.92       P5       44.8     % P3.75       \n",
      "ü•à      Max VERSTAPPEN         4.16       P3       72.3     % P3.60       \n",
      "ü•â      George RUSSELL         4.92       P5       22.6     % P4.00       \n",
      "P4     Lando NORRIS           5.10       P5       56.1     % P2.40       \n",
      "P5     Lewis HAMILTON         5.12       P8       18.3     % P6.25       \n",
      "P6     Oscar PIASTRI          6.08       P6       38.1     % P3.20       \n",
      "P7     Andrea Kimi ANTONELLI  7.60       P16      0.0      % P4.00       \n",
      "P8     Kimi ANTONELLI         7.94       P8       12.5     % P6.50       \n",
      "P9     Carlos SAINZ           8.83       P7       22.4     % P11.25      \n",
      "P10    Fernando ALONSO        9.91       P9       13.6     % P10.20      \n",
      "\n",
      "================================================================================\n",
      "üèÅ PREDICTED PODIUM (TOP 3)\n",
      "================================================================================\n",
      "ü•á 1st    | Charles LECLERC      | Predicted: P3.92 | Grid: P5\n",
      "ü•à 2nd    | Max VERSTAPPEN       | Predicted: P4.16 | Grid: P3\n",
      "ü•â 3rd    | George RUSSELL       | Predicted: P4.92 | Grid: P5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    grid = {\n",
    "        'Max VERSTAPPEN': 2,\n",
    "        'Charles LECLERC': 9,\n",
    "        'Lando NORRIS': 1,\n",
    "        'Carlos SAINZ': 3,\n",
    "        'George RUSSELL': 4,\n",
    "        'Oscar PIASTRI': 5,\n",
    "        'Liam LAWSON': 6,\n",
    "        'Fernando ALONSO': 7,\n",
    "        'Isack HADJAR': 8,\n",
    "        'Charles LECLERC': 9,\n",
    "        'Pierre GASLY': 10,\n",
    "        'Nico HULKENBERG': 11,\n",
    "        'Lance STROLL': 12,\n",
    "        'Esteban OCON': 13,\n",
    "        'Oliver BEARMAN': 14,\n",
    "        'Franco COLAPINTO': 15,\n",
    "        'Alexander ALBON': 16,\n",
    "        'Kimi ANTONELLI': 17,\n",
    "        'Gabriel BORTOLETO': 18,\n",
    "        'Yuki TSUNODA': 19,\n",
    "        'Lewis HAMILTON': 20\n",
    "    }\n",
    "    results = predict_race_results(\n",
    "    race_name=\"Las Vegas Grand Prix\",\n",
    "    track_name=\"Las Vegas\",\n",
    "    year=2025,\n",
    "    grid_positions=grid,\n",
    "    weather='dry'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
